Web Scrapper VIP Commerce
==========================

Pequeno scrapper para baixar imagens de produtos do portal VIP Commerce usando a API Urbanic.

Este reposit√≥rio cont√©m um script que baixa imagens de produtos diretamente da API de integra√ß√£o da Urbanic. **N√£o requer Selenium, Chrome ou interface gr√°fica** ‚Äî funciona puramente com requisi√ß√µes HTTP.

√çndice
------

- **M√©todo Novo (Recomendado)**: API-based downloader
- M√©todo Antigo (Legado): Selenium-based scraper
- Como rodar
- Configura√ß√£o

---

## üöÄ M√©todo Novo (Recomendado): API-based Downloader

**Vantagens:**
- ‚úÖ Muito mais r√°pido (sem overhead de navegador)
- ‚úÖ Roda em qualquer VM (sem necessidade de GUI/Chrome)
- ‚úÖ Depend√™ncias m√≠nimas (apenas requests, tqdm, urllib3)
- ‚úÖ Mais confi√°vel (dados diretos da API)

### Requisitos

Apenas Python 3.7+ e as depend√™ncias m√≠nimas:

```bash
pip install -r requirements-minimal.txt
```

### Como rodar

```bash
python3 -m src.download_images_api
```

O script:
1. Busca todos os produtos da API Urbanic (com pagina√ß√£o autom√°tica)
2. Extrai as URLs das imagens (prefer√™ncia por tamanho 250px, sen√£o a maior dispon√≠vel)
3. Baixa em paralelo (8 workers) para `src/assets/raw_images/`
4. Nomeia cada imagem pelo `codigo_erp.jpg`

### Configura√ß√£o

Edite as constantes no topo de `src/download_images_api.py`:
- `PREFERRED_IMAGE_SIZE = 250` ‚Äî tamanho preferido (250, 500, 144, 60)
- `MAX_WORKERS = 8` ‚Äî n√∫mero de downloads paralelos
- `API_ENDPOINT` ‚Äî URL da API (j√° configurado)

---

## üì¶ M√©todo Antigo (Legado): Selenium-based Scraper

**‚ö†Ô∏è Apenas para refer√™ncia.** Use o m√©todo API acima, que √© muito superior.

### Requisitos (bibliotecas do sistema)

O Chrome headless (ou a build do Chromium) com o chromedriver precisa das bibliotecas abaixo em sistemas Debian/Ubuntu. Execute como root/ sudo:

```
sudo apt-get update && sudo apt-get install -y \
    libglib2.0-0t64 \
    libnss3 \
    libfontconfig1 \
    libx11-6 \
    libx11-xcb1 \
    libxcomposite1 \
    libxcursor1 \
    libxdamage1 \
    libxi6 \
    libxtst6 \
    libasound2t64 \
    libatk1.0-0t64 \
    libatk-bridge2.0-0t64 \
    libcups2t64 \
    libdbus-1-3 \
    libdrm2 \
    libgbm1 \
    libgtk-3-0t64 \
    libpango-1.0-0 \
    libpangocairo-1.0-0 \
    libxfixes3 \
    libxrandr2 \
    libxss1 \
    at-spi2-core
```

Observa√ß√£o: nomes das bibliotecas podem variar entre distribui√ß√µes/vers√µes ‚Äî use o package manager da sua distro quando necess√°rio.

### Estrutura de assets (Selenium legado)

O projeto espera encontrar os bin√°rios do Chrome/Chromium e do Chromedriver dentro da pasta `src/assets` (j√° organizada no repo). A estrutura deve ser:

- `src/assets/chrome-linux64/chrome` ‚Äî execut√°vel do Chrome/Chromium (marcar como execut√°vel)
- `src/assets/chromedriver-linux64/chromedriver` ‚Äî bin√°rio do chromedriver compat√≠vel (marcar como execut√°vel)
- `src/assets/data/product_map.json` ‚Äî mapa de produtos (chave: product_id, valor: codigo_erp)
- `src/assets/raw_images/` ‚Äî pasta onde as imagens baixadas ser√£o salvas (criada automaticamente)

Certifique-se de que os bin√°rios t√™m permiss√£o de execu√ß√£o:

```
chmod +x src/assets/chrome-linux64/chrome src/assets/chromedriver-linux64/chromedriver
```

### Como rodar (Selenium legado)

```bash
pip install -r requirements.txt
python3 -m src.download_images
```

---

## üìù Notas

O c√≥digo carrega algumas constantes de `src/utils/config.py`. O mais importante √© o `DOMAIN_KEY` (o dom√≠nio base do site). Voc√™ pode configur√°-lo de duas formas:

1) Usando um arquivo `.env` na raiz do projeto (recomendado):

```
# .env (exemplo)
DOMAIN_KEY=supervillesupermercado.com.br
# AUTH_TOKEN=...
# API_BASE_URL=...
```

## üìä Performance

Resultados t√≠picos (~9000 produtos):
- **M√©todo API**: ~2-5 minutos (depende da banda e workers)
- **M√©todo Selenium (legado)**: ~30-60 minutos